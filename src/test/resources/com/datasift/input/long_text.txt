We'd like you to demonstrate how a tokenization algorithm could be used to create a
"concordance". A concordance is a bit like an index: It's an alphabetical list of all the words
present in a body of text, complete with citations of where each word appears (e.g., the line,
page or sentence number). Using the programming language of your choice - ideally Scala,
Java or Go as they are widely-used at DataSift - write a program that will read a document from
stdin and generate a concordance that is printed to stdout. The printed format should at least
consist of a sorted list of citations with the frequency and sequence of zero-indexed sentence
numbers where that word occurs.